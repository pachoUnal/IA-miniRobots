{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ClasificaciÃ³n de textos\n",
        "\n",
        "* Francisco Josse Roja Rojas (frrojasr@unal.edu.co)\n",
        "* Yeira Liseth RodrÃ­guez RodrÃ­guez (yrodriguezro@unal.edu.co)\n",
        "<br>\n",
        "<br>\n",
        "A continuaciÃ³n se presenta el desarrollo del tercer ejercicio del capÃ­tulo 5 de redes neuronales. Para ello se uso el dataset Reuters de TensorFlow, que contiene 11,228 noticias clasificadas en 46 categorÃ­as temÃ¡ticas\n",
        "\n",
        "#### 1. Cargar y explorar el dataset\n",
        "El conjunto de datos Reuters contiene textos ya tokenizados (cada palabra ha sido transformada en un nÃºmero entero segÃºn su frecuencia). AquÃ­ se usa solo las 10,000 palabras mÃ¡s frecuentes para evitar ruido y facilitar el entrenamiento."
      ],
      "metadata": {
        "id": "ABiBwN6By0Bu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsoAppEDxz7B",
        "outputId": "990fd64f-c481-4a4f-b126-27d3aeeaf41f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "\u001b[1m2110848/2110848\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "NÃºmero de muestras de entrenamiento: 8982\n",
            "NÃºmero de muestras de prueba: 2246\n",
            "Ejemplo de entrada (tokenizada): [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "Etiqueta asociada: 3\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Cargar el dataset\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000)\n",
        "\n",
        "# Mostrar tamaÃ±o de los conjuntos\n",
        "print(f\"NÃºmero de muestras de entrenamiento: {len(x_train)}\")\n",
        "print(f\"NÃºmero de muestras de prueba: {len(x_test)}\")\n",
        "print(f\"Ejemplo de entrada (tokenizada): {x_train[0]}\")\n",
        "print(f\"Etiqueta asociada: {y_train[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Procesamiento\n",
        "Los textos tienen longitudes variables, por lo que usamos padding para que todos tengan 200 palabras. Esto es necesario para que la red pueda procesarlos como vectores de igual tamaÃ±o. Las etiquetas se convierten a categorÃ­as one-hot para usar `categorical_crossentropy`."
      ],
      "metadata": {
        "id": "kXszub5lzV2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding: igualar longitud de todas las secuencias\n",
        "maxlen = 200\n",
        "x_train_pad = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test_pad = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# One-hot encoding de las etiquetas (46 clases)\n",
        "num_classes = max(y_train) + 1\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "_yqWSdWTzYkK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. ConstrucciÃ³n de la red neuronal\n",
        "* `Embedding`: convierte cada palabra (nÃºmero) en un vector de tamaÃ±o 64, permitiendo al modelo aprender representaciones semÃ¡nticas.\n",
        "\n",
        "* `Flatten`: aplanamos para alimentar a una capa densa.\n",
        "\n",
        "* `Dense + ReLU`: capa oculta de 128 neuronas.\n",
        "\n",
        "* `Dropout`: ayuda a reducir overfitting.\n",
        "\n",
        "* `Dense + softmax`: capa final para clasificar entre 46 temas."
      ],
      "metadata": {
        "id": "B-djTq_Hzf7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=64, input_shape=(maxlen,)),  # entrada explÃ­cita\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),           # capa adicional\n",
        "    Dropout(0.3),                            # dropout mÃ¡s conservador\n",
        "    Dense(46, activation='softmax')         # salida multicategorÃ­a\n",
        "])\n",
        "\n",
        "# Construir manualmente para que summary funcione correctamente\n",
        "model.build(input_shape=(None, maxlen))\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "kfjZ7-hSzfE1",
        "outputId": "ffc35907-ed12-4923-c3e7-620be19f5563"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚       \u001b[38;5;34m640,000\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚     \u001b[38;5;34m1,638,528\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             â”‚         \u001b[38;5;34m2,990\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,638,528</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,990</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,289,774\u001b[0m (8.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,289,774</span> (8.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,289,774\u001b[0m (8.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,289,774</span> (8.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Entrenamiento del modelo\n",
        "Se entrena el modelo usando el 80% del conjunto de entrenamiento y reservamos el 20% para validaciÃ³n. Esto permite monitorear si el modelo estÃ¡ sobreajustando (overfitting).\n",
        "\n"
      ],
      "metadata": {
        "id": "EAVTdFj0z0P-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_pad, y_train_cat,\n",
        "                    epochs=20,                     # mÃ¡s Ã©pocas\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ05g2ySz5CP",
        "outputId": "575ddf4b-a25f-49d5-a0b8-eede94ee08ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - accuracy: 0.3009 - loss: 2.9512 - val_accuracy: 0.5181 - val_loss: 1.8216\n",
            "Epoch 2/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.5551 - loss: 1.7763 - val_accuracy: 0.6049 - val_loss: 1.5478\n",
            "Epoch 3/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6762 - loss: 1.3028 - val_accuracy: 0.6578 - val_loss: 1.3927\n",
            "Epoch 4/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.7845 - loss: 0.9012 - val_accuracy: 0.6772 - val_loss: 1.3617\n",
            "Epoch 5/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.8629 - loss: 0.5936 - val_accuracy: 0.6728 - val_loss: 1.4530\n",
            "Epoch 6/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - accuracy: 0.8997 - loss: 0.4251 - val_accuracy: 0.6800 - val_loss: 1.4855\n",
            "Epoch 7/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.9308 - loss: 0.3105 - val_accuracy: 0.6778 - val_loss: 1.6069\n",
            "Epoch 8/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.9461 - loss: 0.2302 - val_accuracy: 0.6811 - val_loss: 1.6068\n",
            "Epoch 9/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.9620 - loss: 0.1656 - val_accuracy: 0.6889 - val_loss: 1.6451\n",
            "Epoch 10/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.9649 - loss: 0.1449 - val_accuracy: 0.6900 - val_loss: 1.7057\n",
            "Epoch 11/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.9654 - loss: 0.1311 - val_accuracy: 0.6822 - val_loss: 1.7415\n",
            "Epoch 12/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.9679 - loss: 0.1122 - val_accuracy: 0.6861 - val_loss: 1.7165\n",
            "Epoch 13/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9659 - loss: 0.1118 - val_accuracy: 0.6828 - val_loss: 1.8464\n",
            "Epoch 14/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9694 - loss: 0.0992 - val_accuracy: 0.6828 - val_loss: 1.9183\n",
            "Epoch 15/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.9674 - loss: 0.1032 - val_accuracy: 0.6811 - val_loss: 1.8572\n",
            "Epoch 16/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.9697 - loss: 0.0973 - val_accuracy: 0.6878 - val_loss: 1.8982\n",
            "Epoch 17/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.9694 - loss: 0.0872 - val_accuracy: 0.6834 - val_loss: 1.9239\n",
            "Epoch 18/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9697 - loss: 0.0846 - val_accuracy: 0.6839 - val_loss: 1.8812\n",
            "Epoch 19/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.9664 - loss: 0.0921 - val_accuracy: 0.6845 - val_loss: 1.9450\n",
            "Epoch 20/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.9688 - loss: 0.0841 - val_accuracy: 0.6828 - val_loss: 1.9608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. EvaluaciÃ³n del modelo\n",
        "La evaluaciÃ³n nos da una medida objetiva de rendimiento del modelo en datos nuevos. Una buena red deberÃ­a superar el 75-80% de precisiÃ³n con esta arquitectura."
      ],
      "metadata": {
        "id": "ispTGJS5z_Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(x_test_pad, y_test_cat, verbose=0)\n",
        "print(f\"\\nPrecisiÃ³n en test: {acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8mSXtEZ0Dtd",
        "outputId": "c1b9cfae-f8ab-4371-c11c-589f110a9aac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PrecisiÃ³n en test: 67.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Pruebas con base en los pesos aprendidos\n",
        "Se toma una muestra de entrada, se calcula manualmente la activaciÃ³n de la primera capa densa usando los pesos aprendidos y se comparan las predicciones del modelo con la etiqueta real."
      ],
      "metadata": {
        "id": "hqGvISg30Itu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "# 1. Cargar el conjunto de datos\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000)\n",
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "\n",
        "# 2. FunciÃ³n para decodificar texto desde Ã­ndices\n",
        "def decode_text(encoded):\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '<?>') for i in encoded])\n",
        "\n",
        "# 3. Mapeo aproximado de etiquetas a categorÃ­as\n",
        "label_map = {\n",
        "    0:  \"cocoa\", 1:  \"grain\", 2:  \"crude oil\", 3:  \"money-fx\", 4:  \"interest rates\",\n",
        "    5:  \"ship\", 6:  \"trade\", 7:  \"reserves\", 8:  \"cotton\", 9:  \"coffee\",\n",
        "    10: \"sugar\", 11: \"gold\", 12: \"tin\", 13: \"strategic metals\", 14: \"money-supply\",\n",
        "    15: \"income\", 16: \"GNP\", 17: \"inflation\", 18: \"bond\", 19: \"housing\",\n",
        "    20: \"jobs\", 21: \"retail\", 22: \"money market\", 23: \"earnings\", 24: \"acquisitions\",\n",
        "    25: \"merger\", 26: \"commodity\", 27: \"bankruptcy\", 28: \"investment\", 29: \"legal\",\n",
        "    30: \"budget\", 31: \"defense\", 32: \"energy\", 33: \"strategic reserve\", 34: \"natural gas\",\n",
        "    35: \"petrochemicals\", 36: \"opec\", 37: \"economy\", 38: \"finance\", 39: \"real estate\",\n",
        "    40: \"automobile\", 41: \"transportation\", 42: \"food\", 43: \"textile\", 44: \"electronics\", 45: \"tourism\"\n",
        "}\n",
        "\n",
        "# 4. Preprocesamiento (asegÃºrate que estos pasos ya se hicieron antes de entrenar el modelo)\n",
        "maxlen = 200\n",
        "x_test_pad = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# 5. Seleccionar una muestra para prueba\n",
        "sample_idx = 0\n",
        "input_sample = x_test_pad[sample_idx:sample_idx+1]\n",
        "original_encoded = x_test[sample_idx]\n",
        "decoded_text = decode_text(original_encoded)\n",
        "true_label = y_test[sample_idx]\n",
        "\n",
        "# 6. Obtener activaciones manualmente desde el modelo\n",
        "weights, biases = model.layers[2].get_weights()  # primera capa densa\n",
        "embedding_output = model.layers[0](input_sample)\n",
        "flattened = model.layers[1](embedding_output)\n",
        "flattened_np = flattened.numpy()\n",
        "z = np.dot(flattened_np, weights) + biases\n",
        "a = np.maximum(0, z)  # ReLU activaciÃ³n\n",
        "\n",
        "# 7. PredicciÃ³n del modelo\n",
        "y_pred = model.predict(input_sample, verbose=0)\n",
        "predicted_label = np.argmax(y_pred)\n",
        "top3_probs = np.round(np.sort(y_pred[0])[-3:][::-1], 3)\n",
        "top3_classes = np.argsort(y_pred[0])[-3:][::-1]\n",
        "\n",
        "# 8. Mostrar resultados visuales y explicativos\n",
        "print(\"\\nğŸ“° Texto de la noticia (fragmento reconstruido):\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(decoded_text[:500], \"...\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"ğŸ¯ Etiqueta real: {true_label} ({label_map[true_label]})\")\n",
        "print(f\"ğŸ¤– Etiqueta predicha: {predicted_label} ({label_map[predicted_label]})\")\n",
        "\n",
        "print(\"\\nğŸ”¥ Activaciones de la primera capa (primeras 5 neuronas):\")\n",
        "print(np.round(a[0][:5], 3))\n",
        "\n",
        "print(\"\\nğŸ“Š Top 3 clases mÃ¡s probables:\")\n",
        "for i in range(3):\n",
        "    label = top3_classes[i]\n",
        "    print(f\"  Clase {label} ({label_map[label]}) - Probabilidad: {top3_probs[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCDHPNba0VGW",
        "outputId": "e3f17e41-54ca-4f2a-f588-eac30a0fa3c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“° Texto de la noticia (fragmento reconstruido):\n",
            "--------------------------------------------------\n",
            "<?> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <?> growth and expansion plans for <?> inc and <?> inc over the next two years a and p said the acquisition of <?> in august 1986 and <?> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 4 ...\n",
            "--------------------------------------------------\n",
            "ğŸ¯ Etiqueta real: 3 (money-fx)\n",
            "ğŸ¤– Etiqueta predicha: 3 (money-fx)\n",
            "\n",
            "ğŸ”¥ Activaciones de la primera capa (primeras 5 neuronas):\n",
            "[1.677 1.548 0.699 1.536 2.083]\n",
            "\n",
            "ğŸ“Š Top 3 clases mÃ¡s probables:\n",
            "  Clase 3 (money-fx) - Probabilidad: 0.8169999718666077\n",
            "  Clase 4 (interest rates) - Probabilidad: 0.17299999296665192\n",
            "  Clase 20 (jobs) - Probabilidad: 0.004000000189989805\n"
          ]
        }
      ]
    }
  ]
}