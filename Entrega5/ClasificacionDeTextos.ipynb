{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificación de textos\n",
        "\n",
        "* Francisco Josse Roja Rojas (frrojasr@unal.edu.co)\n",
        "* Yeira Liseth Rodríguez Rodríguez (yrodriguezro@unal.edu.co)\n",
        "<br>\n",
        "<br>\n",
        "A continuación se presenta el desarrollo del tercer ejercicio del capítulo 5 de redes neuronales. Para ello se uso el dataset Reuters de TensorFlow, que contiene 11,228 noticias clasificadas en 46 categorías temáticas\n",
        "\n",
        "#### 1. Cargar y explorar el dataset\n",
        "El conjunto de datos Reuters contiene textos ya tokenizados (cada palabra ha sido transformada en un número entero según su frecuencia). Aquí se usa solo las 10,000 palabras más frecuentes para evitar ruido y facilitar el entrenamiento."
      ],
      "metadata": {
        "id": "ABiBwN6By0Bu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsoAppEDxz7B",
        "outputId": "990fd64f-c481-4a4f-b126-27d3aeeaf41f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "\u001b[1m2110848/2110848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Número de muestras de entrenamiento: 8982\n",
            "Número de muestras de prueba: 2246\n",
            "Ejemplo de entrada (tokenizada): [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "Etiqueta asociada: 3\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Cargar el dataset\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000)\n",
        "\n",
        "# Mostrar tamaño de los conjuntos\n",
        "print(f\"Número de muestras de entrenamiento: {len(x_train)}\")\n",
        "print(f\"Número de muestras de prueba: {len(x_test)}\")\n",
        "print(f\"Ejemplo de entrada (tokenizada): {x_train[0]}\")\n",
        "print(f\"Etiqueta asociada: {y_train[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Procesamiento\n",
        "Los textos tienen longitudes variables, por lo que usamos padding para que todos tengan 200 palabras. Esto es necesario para que la red pueda procesarlos como vectores de igual tamaño. Las etiquetas se convierten a categorías one-hot para usar `categorical_crossentropy`."
      ],
      "metadata": {
        "id": "kXszub5lzV2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding: igualar longitud de todas las secuencias\n",
        "maxlen = 200\n",
        "x_train_pad = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test_pad = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# One-hot encoding de las etiquetas (46 clases)\n",
        "num_classes = max(y_train) + 1\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "_yqWSdWTzYkK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Construcción de la red neuronal\n",
        "* `Embedding`: convierte cada palabra (número) en un vector de tamaño 64, permitiendo al modelo aprender representaciones semánticas.\n",
        "\n",
        "* `Flatten`: aplanamos para alimentar a una capa densa.\n",
        "\n",
        "* `Dense + ReLU`: capa oculta de 128 neuronas.\n",
        "\n",
        "* `Dropout`: ayuda a reducir overfitting.\n",
        "\n",
        "* `Dense + softmax`: capa final para clasificar entre 46 temas."
      ],
      "metadata": {
        "id": "B-djTq_Hzf7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=64, input_shape=(maxlen,)),  # entrada explícita\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),           # capa adicional\n",
        "    Dropout(0.3),                            # dropout más conservador\n",
        "    Dense(46, activation='softmax')         # salida multicategoría\n",
        "])\n",
        "\n",
        "# Construir manualmente para que summary funcione correctamente\n",
        "model.build(input_shape=(None, maxlen))\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "kfjZ7-hSzfE1",
        "outputId": "ffc35907-ed12-4923-c3e7-620be19f5563"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m640,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,638,528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             │         \u001b[38;5;34m2,990\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,638,528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,990</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,289,774\u001b[0m (8.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,289,774</span> (8.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,289,774\u001b[0m (8.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,289,774</span> (8.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Entrenamiento del modelo\n",
        "Se entrena el modelo usando el 80% del conjunto de entrenamiento y reservamos el 20% para validación. Esto permite monitorear si el modelo está sobreajustando (overfitting).\n",
        "\n"
      ],
      "metadata": {
        "id": "EAVTdFj0z0P-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_pad, y_train_cat,\n",
        "                    epochs=20,                     # más épocas\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ05g2ySz5CP",
        "outputId": "575ddf4b-a25f-49d5-a0b8-eede94ee08ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - accuracy: 0.3009 - loss: 2.9512 - val_accuracy: 0.5181 - val_loss: 1.8216\n",
            "Epoch 2/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.5551 - loss: 1.7763 - val_accuracy: 0.6049 - val_loss: 1.5478\n",
            "Epoch 3/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6762 - loss: 1.3028 - val_accuracy: 0.6578 - val_loss: 1.3927\n",
            "Epoch 4/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.7845 - loss: 0.9012 - val_accuracy: 0.6772 - val_loss: 1.3617\n",
            "Epoch 5/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.8629 - loss: 0.5936 - val_accuracy: 0.6728 - val_loss: 1.4530\n",
            "Epoch 6/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - accuracy: 0.8997 - loss: 0.4251 - val_accuracy: 0.6800 - val_loss: 1.4855\n",
            "Epoch 7/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.9308 - loss: 0.3105 - val_accuracy: 0.6778 - val_loss: 1.6069\n",
            "Epoch 8/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.9461 - loss: 0.2302 - val_accuracy: 0.6811 - val_loss: 1.6068\n",
            "Epoch 9/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.9620 - loss: 0.1656 - val_accuracy: 0.6889 - val_loss: 1.6451\n",
            "Epoch 10/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.9649 - loss: 0.1449 - val_accuracy: 0.6900 - val_loss: 1.7057\n",
            "Epoch 11/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.9654 - loss: 0.1311 - val_accuracy: 0.6822 - val_loss: 1.7415\n",
            "Epoch 12/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.9679 - loss: 0.1122 - val_accuracy: 0.6861 - val_loss: 1.7165\n",
            "Epoch 13/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9659 - loss: 0.1118 - val_accuracy: 0.6828 - val_loss: 1.8464\n",
            "Epoch 14/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9694 - loss: 0.0992 - val_accuracy: 0.6828 - val_loss: 1.9183\n",
            "Epoch 15/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.9674 - loss: 0.1032 - val_accuracy: 0.6811 - val_loss: 1.8572\n",
            "Epoch 16/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.9697 - loss: 0.0973 - val_accuracy: 0.6878 - val_loss: 1.8982\n",
            "Epoch 17/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.9694 - loss: 0.0872 - val_accuracy: 0.6834 - val_loss: 1.9239\n",
            "Epoch 18/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9697 - loss: 0.0846 - val_accuracy: 0.6839 - val_loss: 1.8812\n",
            "Epoch 19/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.9664 - loss: 0.0921 - val_accuracy: 0.6845 - val_loss: 1.9450\n",
            "Epoch 20/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.9688 - loss: 0.0841 - val_accuracy: 0.6828 - val_loss: 1.9608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Evaluación del modelo\n",
        "La evaluación nos da una medida objetiva de rendimiento del modelo en datos nuevos. Una buena red debería superar el 75-80% de precisión con esta arquitectura."
      ],
      "metadata": {
        "id": "ispTGJS5z_Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(x_test_pad, y_test_cat, verbose=0)\n",
        "print(f\"\\nPrecisión en test: {acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8mSXtEZ0Dtd",
        "outputId": "c1b9cfae-f8ab-4371-c11c-589f110a9aac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Precisión en test: 67.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Pruebas con base en los pesos aprendidos\n",
        "Se toma una muestra de entrada, se calcula manualmente la activación de la primera capa densa usando los pesos aprendidos y se comparan las predicciones del modelo con la etiqueta real."
      ],
      "metadata": {
        "id": "hqGvISg30Itu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "# 1. Cargar el conjunto de datos\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000)\n",
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "\n",
        "# 2. Función para decodificar texto desde índices\n",
        "def decode_text(encoded):\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '<?>') for i in encoded])\n",
        "\n",
        "# 3. Mapeo aproximado de etiquetas a categorías\n",
        "label_map = {\n",
        "    0:  \"cocoa\", 1:  \"grain\", 2:  \"crude oil\", 3:  \"money-fx\", 4:  \"interest rates\",\n",
        "    5:  \"ship\", 6:  \"trade\", 7:  \"reserves\", 8:  \"cotton\", 9:  \"coffee\",\n",
        "    10: \"sugar\", 11: \"gold\", 12: \"tin\", 13: \"strategic metals\", 14: \"money-supply\",\n",
        "    15: \"income\", 16: \"GNP\", 17: \"inflation\", 18: \"bond\", 19: \"housing\",\n",
        "    20: \"jobs\", 21: \"retail\", 22: \"money market\", 23: \"earnings\", 24: \"acquisitions\",\n",
        "    25: \"merger\", 26: \"commodity\", 27: \"bankruptcy\", 28: \"investment\", 29: \"legal\",\n",
        "    30: \"budget\", 31: \"defense\", 32: \"energy\", 33: \"strategic reserve\", 34: \"natural gas\",\n",
        "    35: \"petrochemicals\", 36: \"opec\", 37: \"economy\", 38: \"finance\", 39: \"real estate\",\n",
        "    40: \"automobile\", 41: \"transportation\", 42: \"food\", 43: \"textile\", 44: \"electronics\", 45: \"tourism\"\n",
        "}\n",
        "\n",
        "# 4. Preprocesamiento (asegúrate que estos pasos ya se hicieron antes de entrenar el modelo)\n",
        "maxlen = 200\n",
        "x_test_pad = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# 5. Seleccionar una muestra para prueba\n",
        "sample_idx = 0\n",
        "input_sample = x_test_pad[sample_idx:sample_idx+1]\n",
        "original_encoded = x_test[sample_idx]\n",
        "decoded_text = decode_text(original_encoded)\n",
        "true_label = y_test[sample_idx]\n",
        "\n",
        "# 6. Obtener activaciones manualmente desde el modelo\n",
        "weights, biases = model.layers[2].get_weights()  # primera capa densa\n",
        "embedding_output = model.layers[0](input_sample)\n",
        "flattened = model.layers[1](embedding_output)\n",
        "flattened_np = flattened.numpy()\n",
        "z = np.dot(flattened_np, weights) + biases\n",
        "a = np.maximum(0, z)  # ReLU activación\n",
        "\n",
        "# 7. Predicción del modelo\n",
        "y_pred = model.predict(input_sample, verbose=0)\n",
        "predicted_label = np.argmax(y_pred)\n",
        "top3_probs = np.round(np.sort(y_pred[0])[-3:][::-1], 3)\n",
        "top3_classes = np.argsort(y_pred[0])[-3:][::-1]\n",
        "\n",
        "# 8. Mostrar resultados visuales y explicativos\n",
        "print(\"\\n📰 Texto de la noticia (fragmento reconstruido):\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(decoded_text[:500], \"...\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"🎯 Etiqueta real: {true_label} ({label_map[true_label]})\")\n",
        "print(f\"🤖 Etiqueta predicha: {predicted_label} ({label_map[predicted_label]})\")\n",
        "\n",
        "print(\"\\n🔥 Activaciones de la primera capa (primeras 5 neuronas):\")\n",
        "print(np.round(a[0][:5], 3))\n",
        "\n",
        "print(\"\\n📊 Top 3 clases más probables:\")\n",
        "for i in range(3):\n",
        "    label = top3_classes[i]\n",
        "    print(f\"  Clase {label} ({label_map[label]}) - Probabilidad: {top3_probs[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCDHPNba0VGW",
        "outputId": "e3f17e41-54ca-4f2a-f588-eac30a0fa3c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📰 Texto de la noticia (fragmento reconstruido):\n",
            "--------------------------------------------------\n",
            "<?> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <?> growth and expansion plans for <?> inc and <?> inc over the next two years a and p said the acquisition of <?> in august 1986 and <?> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 4 ...\n",
            "--------------------------------------------------\n",
            "🎯 Etiqueta real: 3 (money-fx)\n",
            "🤖 Etiqueta predicha: 3 (money-fx)\n",
            "\n",
            "🔥 Activaciones de la primera capa (primeras 5 neuronas):\n",
            "[1.677 1.548 0.699 1.536 2.083]\n",
            "\n",
            "📊 Top 3 clases más probables:\n",
            "  Clase 3 (money-fx) - Probabilidad: 0.8169999718666077\n",
            "  Clase 4 (interest rates) - Probabilidad: 0.17299999296665192\n",
            "  Clase 20 (jobs) - Probabilidad: 0.004000000189989805\n"
          ]
        }
      ]
    }
  ]
}